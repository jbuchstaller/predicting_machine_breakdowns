{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pp\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "get_ipython().magic(u'matplotlib inline')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inspecting sensor data, remove empty columns and change datatype\n",
    "data = pd.read_csv('sensor.csv')\n",
    "#data.info()\n",
    "#remove old index and column without any data\n",
    "data = data.drop(['Unnamed: 0','sensor_15'], axis=1)\n",
    "#convert date to datetime for timeseries and set as new index\n",
    "data[['timestamp']] = data[['timestamp']].apply(pd.to_datetime)\n",
    "ts = data.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2018-04-12 21:55:00'),\n",
       " Timestamp('2018-04-18 00:30:00'),\n",
       " Timestamp('2018-05-19 03:18:00'),\n",
       " Timestamp('2018-05-25 00:30:00'),\n",
       " Timestamp('2018-06-28 22:00:00'),\n",
       " Timestamp('2018-07-08 00:11:00'),\n",
       " Timestamp('2018-07-25 14:00:00')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check at which timepoints the machine was broken\n",
    "ts_broken = ts[ts.machine_status == 'BROKEN']\n",
    "list(ts_broken.index)\n",
    "#the machine was broken at seven timepoints during 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a new class \"before breaking/broken\" : 10 minutes before breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fill in missing values, default is 'linear', treat values as equally spaced\n",
    "ts_interpolated = ts.interpolate()\n",
    "\n",
    "# create a new class \"before breaking/broken\" : 10 minutes before breakdown\n",
    "temp = ts_interpolated['machine_status'].copy()\n",
    "\n",
    "temp.loc[(temp.index >= pd.to_datetime('2018-04-12 21:45:00')) & (temp.index <= pd.to_datetime('2018-04-12 21:54:00'))] = 'BEFORE_BREAKING'\n",
    "temp.loc[(temp.index >= pd.to_datetime('2018-04-18 00:20:00')) & (temp.index <= pd.to_datetime('2018-04-18 00:29:00'))] = 'BEFORE_BREAKING'\n",
    "temp.loc[(temp.index >= pd.to_datetime('2018-05-19 03:08:00')) & (temp.index <= pd.to_datetime('2018-05-19 03:17:00'))] = 'BEFORE_BREAKING'\n",
    "temp.loc[(temp.index >= pd.to_datetime('2018-05-25 00:20:00')) & (temp.index <= pd.to_datetime('2018-05-25 00:29:00'))] = 'BEFORE_BREAKING'\n",
    "temp.loc[(temp.index >= pd.to_datetime('2018-06-28 21:50:00')) & (temp.index <= pd.to_datetime('2018-06-28 21:59:00'))] = 'BEFORE_BREAKING'\n",
    "temp.loc[(temp.index >= pd.to_datetime('2018-07-08 00:01:00')) & (temp.index <= pd.to_datetime('2018-07-08 00:10:00'))] = 'BEFORE_BREAKING'\n",
    "temp.loc[(temp.index >= pd.to_datetime('2018-07-25 13:50:00')) & (temp.index <= pd.to_datetime('2018-07-25 13:59:00'))] = 'BEFORE_BREAKING'\n",
    "\n",
    "ts_interpolated['machine_status'] = temp\n",
    "\n",
    "#check result\n",
    "#ts_interpolated.info()\n",
    "#ts_interpolated[ts_interpolated['machine_status'] == 'BEFORE_BREAKING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# unite 'before_breaking', 'broken' and 'recovering' to detect the abnormal classes : make it 3 class problem \n",
    "def make_status_abnormal(alarms): \n",
    "    if np.any(alarms == 'BEFORE_BREAKING'):\n",
    "        return 1\n",
    "    if np.any(alarms == 'BROKEN'):\n",
    "        return 1\n",
    "    if np.any(alarms == 'NORMAL'):\n",
    "        return 0\n",
    "    if np.any(alarms == 'RECOVERING'):\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add new classes to dataframe\n",
    "ts_interpolated['machine_status_new'] = ts_interpolated['machine_status'].apply(make_status_abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check result\n",
    "#ts_interpolated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    205766\n",
       "2     14477\n",
       "1        77\n",
       "Name: machine_status_new, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_interpolated['machine_status_new'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sensor_00',\n",
       " 'sensor_01',\n",
       " 'sensor_02',\n",
       " 'sensor_03',\n",
       " 'sensor_04',\n",
       " 'sensor_05',\n",
       " 'sensor_06',\n",
       " 'sensor_07',\n",
       " 'sensor_08',\n",
       " 'sensor_09',\n",
       " 'sensor_10',\n",
       " 'sensor_11',\n",
       " 'sensor_12',\n",
       " 'sensor_13',\n",
       " 'sensor_14',\n",
       " 'sensor_16',\n",
       " 'sensor_17',\n",
       " 'sensor_18',\n",
       " 'sensor_19',\n",
       " 'sensor_20',\n",
       " 'sensor_21',\n",
       " 'sensor_22',\n",
       " 'sensor_23',\n",
       " 'sensor_24',\n",
       " 'sensor_25',\n",
       " 'sensor_26',\n",
       " 'sensor_27',\n",
       " 'sensor_28',\n",
       " 'sensor_29',\n",
       " 'sensor_30',\n",
       " 'sensor_31',\n",
       " 'sensor_32',\n",
       " 'sensor_33',\n",
       " 'sensor_34',\n",
       " 'sensor_35',\n",
       " 'sensor_36',\n",
       " 'sensor_37',\n",
       " 'sensor_38',\n",
       " 'sensor_39',\n",
       " 'sensor_40',\n",
       " 'sensor_41',\n",
       " 'sensor_42',\n",
       " 'sensor_43',\n",
       " 'sensor_44',\n",
       " 'sensor_45',\n",
       " 'sensor_46',\n",
       " 'sensor_47',\n",
       " 'sensor_48',\n",
       " 'sensor_49',\n",
       " 'sensor_50',\n",
       " 'sensor_51',\n",
       " 'machine_status_new',\n",
       " 'machine_status_new_t']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_subset = list(ts_interpolated.columns.values)\n",
    "\n",
    "feature_subset.remove('machine_status')\n",
    "\n",
    "#feature_subset.remove('machine_status_new')\n",
    "\n",
    "feature_subset.append('machine_status_new_t')\n",
    "\n",
    "feature_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert series to supervised learning (code from https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/)\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_interpolated_reframed = series_to_supervised(ts_interpolated, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 220319 entries, 2018-04-01 00:01:00 to 2018-08-31 23:59:00\n",
      "Columns: 106 entries, var1(t-1) to var53(t)\n",
      "dtypes: float64(103), int64(1), object(2)\n",
      "memory usage: 179.9+ MB\n"
     ]
    }
   ],
   "source": [
    "ts_interpolated_reframed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_interpolated_reframed.drop(['var1(t)', 'var2(t)',\n",
    "       'var3(t)', 'var4(t)', 'var5(t)', 'var6(t)', 'var7(t)', 'var8(t)',\n",
    "       'var9(t)', 'var10(t)', 'var11(t)', 'var12(t)', 'var13(t)',\n",
    "       'var14(t)', 'var15(t)', 'var16(t)', 'var17(t)', 'var18(t)',\n",
    "       'var19(t)', 'var20(t)', 'var21(t)', 'var22(t)', 'var23(t)',\n",
    "       'var24(t)', 'var25(t)', 'var26(t)', 'var27(t)', 'var28(t)',\n",
    "       'var29(t)', 'var30(t)', 'var31(t)', 'var32(t)', 'var33(t)',\n",
    "       'var34(t)', 'var35(t)', 'var36(t)', 'var37(t)', 'var38(t)',\n",
    "       'var39(t)', 'var40(t)', 'var41(t)', 'var42(t)', 'var43(t)',\n",
    "       'var44(t)', 'var45(t)', 'var46(t)', 'var47(t)', 'var48(t)',\n",
    "       'var49(t)', 'var50(t)', 'var51(t)', 'var52(t)', 'var52(t-1)'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 220319 entries, 2018-04-01 00:01:00 to 2018-08-31 23:59:00\n",
      "Data columns (total 53 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   var1(t-1)   220319 non-null  float64\n",
      " 1   var2(t-1)   220319 non-null  float64\n",
      " 2   var3(t-1)   220319 non-null  float64\n",
      " 3   var4(t-1)   220319 non-null  float64\n",
      " 4   var5(t-1)   220319 non-null  float64\n",
      " 5   var6(t-1)   220319 non-null  float64\n",
      " 6   var7(t-1)   220319 non-null  float64\n",
      " 7   var8(t-1)   220319 non-null  float64\n",
      " 8   var9(t-1)   220319 non-null  float64\n",
      " 9   var10(t-1)  220319 non-null  float64\n",
      " 10  var11(t-1)  220319 non-null  float64\n",
      " 11  var12(t-1)  220319 non-null  float64\n",
      " 12  var13(t-1)  220319 non-null  float64\n",
      " 13  var14(t-1)  220319 non-null  float64\n",
      " 14  var15(t-1)  220319 non-null  float64\n",
      " 15  var16(t-1)  220319 non-null  float64\n",
      " 16  var17(t-1)  220319 non-null  float64\n",
      " 17  var18(t-1)  220319 non-null  float64\n",
      " 18  var19(t-1)  220319 non-null  float64\n",
      " 19  var20(t-1)  220319 non-null  float64\n",
      " 20  var21(t-1)  220319 non-null  float64\n",
      " 21  var22(t-1)  220319 non-null  float64\n",
      " 22  var23(t-1)  220319 non-null  float64\n",
      " 23  var24(t-1)  220319 non-null  float64\n",
      " 24  var25(t-1)  220319 non-null  float64\n",
      " 25  var26(t-1)  220319 non-null  float64\n",
      " 26  var27(t-1)  220319 non-null  float64\n",
      " 27  var28(t-1)  220319 non-null  float64\n",
      " 28  var29(t-1)  220319 non-null  float64\n",
      " 29  var30(t-1)  220319 non-null  float64\n",
      " 30  var31(t-1)  220319 non-null  float64\n",
      " 31  var32(t-1)  220319 non-null  float64\n",
      " 32  var33(t-1)  220319 non-null  float64\n",
      " 33  var34(t-1)  220319 non-null  float64\n",
      " 34  var35(t-1)  220319 non-null  float64\n",
      " 35  var36(t-1)  220319 non-null  float64\n",
      " 36  var37(t-1)  220319 non-null  float64\n",
      " 37  var38(t-1)  220319 non-null  float64\n",
      " 38  var39(t-1)  220319 non-null  float64\n",
      " 39  var40(t-1)  220319 non-null  float64\n",
      " 40  var41(t-1)  220319 non-null  float64\n",
      " 41  var42(t-1)  220319 non-null  float64\n",
      " 42  var43(t-1)  220319 non-null  float64\n",
      " 43  var44(t-1)  220319 non-null  float64\n",
      " 44  var45(t-1)  220319 non-null  float64\n",
      " 45  var46(t-1)  220319 non-null  float64\n",
      " 46  var47(t-1)  220319 non-null  float64\n",
      " 47  var48(t-1)  220319 non-null  float64\n",
      " 48  var49(t-1)  220319 non-null  float64\n",
      " 49  var50(t-1)  220319 non-null  float64\n",
      " 50  var51(t-1)  220319 non-null  float64\n",
      " 51  var53(t-1)  220319 non-null  float64\n",
      " 52  var53(t)    220319 non-null  int64  \n",
      "dtypes: float64(52), int64(1)\n",
      "memory usage: 90.8 MB\n"
     ]
    }
   ],
   "source": [
    "ts_interpolated_reframed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_interpolated_reframed.columns = feature_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 220319 entries, 2018-04-01 00:01:00 to 2018-08-31 23:59:00\n",
      "Data columns (total 53 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   sensor_00             220319 non-null  float64\n",
      " 1   sensor_01             220319 non-null  float64\n",
      " 2   sensor_02             220319 non-null  float64\n",
      " 3   sensor_03             220319 non-null  float64\n",
      " 4   sensor_04             220319 non-null  float64\n",
      " 5   sensor_05             220319 non-null  float64\n",
      " 6   sensor_06             220319 non-null  float64\n",
      " 7   sensor_07             220319 non-null  float64\n",
      " 8   sensor_08             220319 non-null  float64\n",
      " 9   sensor_09             220319 non-null  float64\n",
      " 10  sensor_10             220319 non-null  float64\n",
      " 11  sensor_11             220319 non-null  float64\n",
      " 12  sensor_12             220319 non-null  float64\n",
      " 13  sensor_13             220319 non-null  float64\n",
      " 14  sensor_14             220319 non-null  float64\n",
      " 15  sensor_16             220319 non-null  float64\n",
      " 16  sensor_17             220319 non-null  float64\n",
      " 17  sensor_18             220319 non-null  float64\n",
      " 18  sensor_19             220319 non-null  float64\n",
      " 19  sensor_20             220319 non-null  float64\n",
      " 20  sensor_21             220319 non-null  float64\n",
      " 21  sensor_22             220319 non-null  float64\n",
      " 22  sensor_23             220319 non-null  float64\n",
      " 23  sensor_24             220319 non-null  float64\n",
      " 24  sensor_25             220319 non-null  float64\n",
      " 25  sensor_26             220319 non-null  float64\n",
      " 26  sensor_27             220319 non-null  float64\n",
      " 27  sensor_28             220319 non-null  float64\n",
      " 28  sensor_29             220319 non-null  float64\n",
      " 29  sensor_30             220319 non-null  float64\n",
      " 30  sensor_31             220319 non-null  float64\n",
      " 31  sensor_32             220319 non-null  float64\n",
      " 32  sensor_33             220319 non-null  float64\n",
      " 33  sensor_34             220319 non-null  float64\n",
      " 34  sensor_35             220319 non-null  float64\n",
      " 35  sensor_36             220319 non-null  float64\n",
      " 36  sensor_37             220319 non-null  float64\n",
      " 37  sensor_38             220319 non-null  float64\n",
      " 38  sensor_39             220319 non-null  float64\n",
      " 39  sensor_40             220319 non-null  float64\n",
      " 40  sensor_41             220319 non-null  float64\n",
      " 41  sensor_42             220319 non-null  float64\n",
      " 42  sensor_43             220319 non-null  float64\n",
      " 43  sensor_44             220319 non-null  float64\n",
      " 44  sensor_45             220319 non-null  float64\n",
      " 45  sensor_46             220319 non-null  float64\n",
      " 46  sensor_47             220319 non-null  float64\n",
      " 47  sensor_48             220319 non-null  float64\n",
      " 48  sensor_49             220319 non-null  float64\n",
      " 49  sensor_50             220319 non-null  float64\n",
      " 50  sensor_51             220319 non-null  float64\n",
      " 51  machine_status_new    220319 non-null  float64\n",
      " 52  machine_status_new_t  220319 non-null  int64  \n",
      "dtypes: float64(52), int64(1)\n",
      "memory usage: 90.8 MB\n"
     ]
    }
   ],
   "source": [
    "ts_interpolated_reframed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#[Timestamp('2018-04-12 21:55:00'),\n",
    " #Timestamp('2018-04-18 00:30:00'),\n",
    "# Timestamp('2018-05-19 03:18:00'),\n",
    "# Timestamp('2018-05-25 00:30:00'),\n",
    "# Timestamp('2018-06-28 22:00:00'),\n",
    "# Timestamp('2018-07-08 00:11:00'),\n",
    "# Timestamp('2018-07-25 14:00:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### RNN with class weights on unsampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#broken sensors\n",
    "#[Timestamp('2018-04-12 21:55:00'),\n",
    "# Timestamp('2018-04-18 00:30:00'),\n",
    "#Timestamp('2018-05-19 03:18:00'),\n",
    "#Timestamp('2018-05-25 00:30:00'),\n",
    "# Timestamp('2018-06-28 22:00:00'),\n",
    "#Timestamp('2018-07-08 00:11:00'),\n",
    "#Timestamp('2018-07-25 14:00:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_interpolated_train = ts_interpolated_reframed['2018-04-01':'2018-06-21']\n",
    "ts_interpolated_valid = ts_interpolated_reframed['2018-06-22':'2018-07-01']\n",
    "ts_interpolated_test = ts_interpolated_reframed['2018-07-02':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_subset.remove('machine_status_new_t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sensor_00',\n",
       " 'sensor_01',\n",
       " 'sensor_02',\n",
       " 'sensor_03',\n",
       " 'sensor_04',\n",
       " 'sensor_05',\n",
       " 'sensor_06',\n",
       " 'sensor_07',\n",
       " 'sensor_08',\n",
       " 'sensor_09',\n",
       " 'sensor_10',\n",
       " 'sensor_11',\n",
       " 'sensor_12',\n",
       " 'sensor_13',\n",
       " 'sensor_14',\n",
       " 'sensor_16',\n",
       " 'sensor_17',\n",
       " 'sensor_18',\n",
       " 'sensor_19',\n",
       " 'sensor_20',\n",
       " 'sensor_21',\n",
       " 'sensor_22',\n",
       " 'sensor_23',\n",
       " 'sensor_24',\n",
       " 'sensor_25',\n",
       " 'sensor_26',\n",
       " 'sensor_27',\n",
       " 'sensor_28',\n",
       " 'sensor_29',\n",
       " 'sensor_30',\n",
       " 'sensor_31',\n",
       " 'sensor_32',\n",
       " 'sensor_33',\n",
       " 'sensor_34',\n",
       " 'sensor_35',\n",
       " 'sensor_36',\n",
       " 'sensor_37',\n",
       " 'sensor_38',\n",
       " 'sensor_39',\n",
       " 'sensor_40',\n",
       " 'sensor_41',\n",
       " 'sensor_42',\n",
       " 'sensor_43',\n",
       " 'sensor_44',\n",
       " 'sensor_45',\n",
       " 'sensor_46',\n",
       " 'sensor_47',\n",
       " 'sensor_48',\n",
       " 'sensor_49',\n",
       " 'sensor_50',\n",
       " 'sensor_51',\n",
       " 'machine_status_new']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = ts_interpolated_train[feature_subset]\n",
    "X_valid = ts_interpolated_valid[feature_subset]\n",
    "X_test = ts_interpolated_test[feature_subset]\n",
    "y_train = ts_interpolated_train['machine_status_new_t']\n",
    "y_valid = ts_interpolated_valid['machine_status_new_t']\n",
    "y_test = ts_interpolated_test['machine_status_new_t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    112064\n",
       "2      5971\n",
       "1        44\n",
       "Name: machine_status_new_t, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_interpolated_train['machine_status_new_t'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9950\n",
       "2    4439\n",
       "1      11\n",
       "Name: machine_status_new_t, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_interpolated_valid['machine_status_new_t'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    83751\n",
       "2     4067\n",
       "1       22\n",
       "Name: machine_status_new_t, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_interpolated_test['machine_status_new_t'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9343888 ,  0.47916635,  0.71046678, ..., -0.06265956,\n",
       "        -0.64726944, -1.        ],\n",
       "       [ 0.9343888 ,  0.47916635,  0.71046678, ..., -0.06265956,\n",
       "        -0.64726944, -1.        ],\n",
       "       [ 0.91817862,  0.49479155,  0.71046678, ..., -0.07033258,\n",
       "        -0.64249478, -1.        ],\n",
       "       ...,\n",
       "       [ 0.96835249,  0.52864535,  0.38084601, ..., -0.47058825,\n",
       "         1.        , -1.        ],\n",
       "       [ 0.96140471,  0.52864535,  0.38084601, ..., -0.47058825,\n",
       "         1.        , -1.        ],\n",
       "       [ 0.96989583,  0.53385395,  0.38084601, ..., -0.46930926,\n",
       "         1.        , -1.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train column names: \n",
      "machine_status_new_t\n",
      "y_valid column names: \n",
      "machine_status_new_t\n",
      "y_test column names: \n",
      "machine_status_new_t\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.DataFrame(y_train)\n",
    "\n",
    "#check column names\n",
    "for col in y_train.columns:\n",
    "    print(\"y_train column names: \")\n",
    "    print(col)\n",
    "    \n",
    "y_valid = pd.DataFrame(y_valid)\n",
    "\n",
    "#check column names\n",
    "for col in y_valid.columns:\n",
    "    print(\"y_valid column names: \")\n",
    "    print(col)\n",
    "    \n",
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "for col in y_test.columns:\n",
    "    print(\"y_test column names: \")\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for LSTM need [samples, timesteps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_reshaped2 = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid_reshaped2 = X_valid.reshape((X_valid.shape[0], 1, X_valid.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_reshaped2 = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118079, 1, 52) (118079, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_reshaped2.shape, y_train.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_valid = np.array(y_valid)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model3 = keras.models.Sequential([\n",
    "    keras.layers.LSTM(6,input_shape=(X_train_reshaped2.shape[1], X_train_reshaped2.shape[2])),\n",
    "    #keras.layers.LSTM(3,return_sequences=True),\n",
    "    #keras.layers.LSTM(3,return_sequences=True),\n",
    "    keras.layers.Dense(3,activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model3.compile(loss='sparse_categorical_crossentropy',optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.35\n",
      "Weight for class 1: 894.55\n",
      "Weight for class 2: 6.59\n"
     ]
    }
   ],
   "source": [
    "total = 112065+5971+44\n",
    "weight_for_0 = (1 / 112065)*(total)/3.0 \n",
    "weight_for_1 = (1 / 44)*(total)/3.0\n",
    "weight_for_2 = (1 / 5971)*(total)/3.0\n",
    "class_weight_by_hand = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
    "print('Weight for class 2: {:.2f}'.format(weight_for_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_weights = {0: 0.35, 1: 895, 2: 6.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118079, 52)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model3.fit(X_train_reshaped2, y_train, \n",
    "                    epochs=20, batch_size=5000,\n",
    "                    validation_data=(X_valid_reshaped2, \n",
    "                                     y_valid),\n",
    "                    class_weight = class_weights,\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse_test3 = model3.evaluate(X_test_reshaped2, np.array(y_test), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3440248112657357, 0.9870674]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ypred3 = model3.predict(X_test_reshaped2)\n",
    "y_pred_single3 = ypred3.argmax(axis = 1)[:,None]\n",
    "y_pred_single_df3 = pd.DataFrame(y_pred_single3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82717,   742,   291],\n",
       "       [    7,    12,     3],\n",
       "       [    0,    93,  3975]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "y_test = ts_interpolated_test['machine_status_new']\n",
    "cnf_matrix_nn_down = metrics.confusion_matrix(y_test, y_pred_single_df3)\n",
    "cnf_matrix_nn_down\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2018-07-02 00:00:00    2.0\n",
       "2018-07-02 00:01:00    2.0\n",
       "2018-07-02 00:02:00    2.0\n",
       "2018-07-02 00:03:00    2.0\n",
       "2018-07-02 00:04:00    2.0\n",
       "                      ... \n",
       "2018-08-31 23:55:00    0.0\n",
       "2018-08-31 23:56:00    0.0\n",
       "2018-08-31 23:57:00    0.0\n",
       "2018-08-31 23:58:00    0.0\n",
       "2018-08-31 23:59:00    0.0\n",
       "Name: machine_status_new, Length: 87840, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use resampling for timeseries\n",
    "#https://link.springer.com/article/10.1007/s41060-017-0044-3\n",
    "#https://datascience.stackexchange.com/questions/28200/when-should-you-balance-a-time-series-dataset\n",
    "##try upsampling only the breakdowns (adding seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#references\n",
    "\n",
    "#https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "##try using the last step\n",
    "\n",
    "#https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data\n",
    "##downsample and upweight\n",
    "\n",
    "#https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "#https://www.tensorflow.org/tutorials/text/text_classification_rnn\n",
    "#https://github.com/ovguyo/moviereview\n",
    "#https://machinelearningmastery.com/what-are-word-embeddings/\n",
    "#https://www.kaggle.com/rajmehra03/a-detailed-explanation-of-keras-embedding-layer\n",
    "####text sentiment classification with LSTM and two classes (using word embeddings)\n",
    "\n",
    "#https://machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/\n",
    "#sequence prediction, not classification :)\n",
    "\n",
    "#https://www.tensorflow.org/guide/keras/sequential_model\n",
    "#basics on sequentual model\n",
    "\n",
    "#https://github.com/keras-team/keras/issues/3653\n",
    "#cant do class weights with multi-class classification\n",
    "\n",
    "#imbalanced 2 class classifier\n",
    "#https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#understanding_useful_metrics\n",
    "\n",
    "#multiclass classifier\n",
    "#https://www.tensorflow.org/tutorials/keras/classification\n",
    "\n",
    "#https://datascience.stackexchange.com/questions/27533/keras-lstm-with-1d-time-series?rq=1\n",
    "#https://datascience.stackexchange.com/questions/77588/setting-batch-size-when-performing-multi-class-classification-with-imbalanced-da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p37new",
   "language": "python",
   "name": "p37new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
